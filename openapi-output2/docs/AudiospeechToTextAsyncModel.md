# AudiospeechToTextAsyncModel


## Properties

Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**voci** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559359244016**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559359244016.md) |  | [optional] 
**voxist** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364706672**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364706672.md) |  | [optional] 
**microsoft** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364707616**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364707616.md) |  | [optional] 
**google** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364246464**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364246464.md) |  | [optional] 
**ibm** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364564096**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364564096.md) |  | [optional] 
**oneai** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364681104**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364681104.md) |  | [optional] 
**revai** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364759392**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364759392.md) |  | [optional] 
**amazon** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559352772784**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559352772784.md) |  | [optional] 
**gladia** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364754576**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364754576.md) |  | [optional] 
**neuralspace** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364731168**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364731168.md) |  | [optional] 
**assembly** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364751808**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364751808.md) |  | [optional] 
**faker** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364782352**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364782352.md) |  | [optional] 
**speechmatics** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364813056**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364813056.md) |  | [optional] 
**symbl** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364816400**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364816400.md) |  | [optional] 
**openai** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364619808**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364619808.md) |  | [optional] 
**deepgram** | [**PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364616432**](PydanticMainAudiospeechToTextAsyncSpeechToTextAsyncDataClass94559364616432.md) |  | [optional] 

## Example

```python
from openapi_client.models.audiospeech_to_text_async_model import AudiospeechToTextAsyncModel

# TODO update the JSON string below
json = "{}"
# create an instance of AudiospeechToTextAsyncModel from a JSON string
audiospeech_to_text_async_model_instance = AudiospeechToTextAsyncModel.from_json(json)
# print the JSON string representation of the object
print(AudiospeechToTextAsyncModel.to_json())

# convert the object into a dict
audiospeech_to_text_async_model_dict = audiospeech_to_text_async_model_instance.to_dict()
# create an instance of AudiospeechToTextAsyncModel from a dict
audiospeech_to_text_async_model_form_dict = audiospeech_to_text_async_model.from_dict(audiospeech_to_text_async_model_dict)
```
[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)


