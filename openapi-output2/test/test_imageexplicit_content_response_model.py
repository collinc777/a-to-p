# coding: utf-8

"""
Eden AI

Your project description

The version of the OpenAPI document: 2.0
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501

import unittest

from openapi_client.models.imageexplicit_content_response_model import (
    ImageexplicitContentResponseModel,
)


class TestImageexplicitContentResponseModel(unittest.TestCase):
    """ImageexplicitContentResponseModel unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> ImageexplicitContentResponseModel:
        """Test ImageexplicitContentResponseModel
        include_option is a boolean, when False only required
        params are included, when True both required and
        optional params are included"""
        # uncomment below to create an instance of `ImageexplicitContentResponseModel`
        """
        model = ImageexplicitContentResponseModel()
        if include_optional:
            return ImageexplicitContentResponseModel(
                microsoft = openapi_client.models.imageexplicit_content_explicit_content_data_class.imageexplicit_contentExplicitContentDataClass(
                    nsfw_likelihood = 56, 
                    nsfw_likelihood_score = 56, 
                    items = [
                        openapi_client.models.explicit_item.ExplicitItem(
                            label = '', 
                            likelihood = 56, 
                            likelihood_score = 56, 
                            category = 'Toxic', 
                            subcategory = null, )
                        ], 
                    original_response = null, 
                    status = null, ),
                google = openapi_client.models.imageexplicit_content_explicit_content_data_class.imageexplicit_contentExplicitContentDataClass(
                    nsfw_likelihood = 56, 
                    nsfw_likelihood_score = 56, 
                    items = [
                        openapi_client.models.explicit_item.ExplicitItem(
                            label = '', 
                            likelihood = 56, 
                            likelihood_score = 56, 
                            category = 'Toxic', 
                            subcategory = null, )
                        ], 
                    original_response = null, 
                    status = null, ),
                picpurify = openapi_client.models.imageexplicit_content_explicit_content_data_class.imageexplicit_contentExplicitContentDataClass(
                    nsfw_likelihood = 56, 
                    nsfw_likelihood_score = 56, 
                    items = [
                        openapi_client.models.explicit_item.ExplicitItem(
                            label = '', 
                            likelihood = 56, 
                            likelihood_score = 56, 
                            category = 'Toxic', 
                            subcategory = null, )
                        ], 
                    original_response = null, 
                    status = null, ),
                amazon = openapi_client.models.imageexplicit_content_explicit_content_data_class.imageexplicit_contentExplicitContentDataClass(
                    nsfw_likelihood = 56, 
                    nsfw_likelihood_score = 56, 
                    items = [
                        openapi_client.models.explicit_item.ExplicitItem(
                            label = '', 
                            likelihood = 56, 
                            likelihood_score = 56, 
                            category = 'Toxic', 
                            subcategory = null, )
                        ], 
                    original_response = null, 
                    status = null, ),
                clarifai = openapi_client.models.imageexplicit_content_explicit_content_data_class.imageexplicit_contentExplicitContentDataClass(
                    nsfw_likelihood = 56, 
                    nsfw_likelihood_score = 56, 
                    items = [
                        openapi_client.models.explicit_item.ExplicitItem(
                            label = '', 
                            likelihood = 56, 
                            likelihood_score = 56, 
                            category = 'Toxic', 
                            subcategory = null, )
                        ], 
                    original_response = null, 
                    status = null, ),
                api4ai = openapi_client.models.imageexplicit_content_explicit_content_data_class.imageexplicit_contentExplicitContentDataClass(
                    nsfw_likelihood = 56, 
                    nsfw_likelihood_score = 56, 
                    items = [
                        openapi_client.models.explicit_item.ExplicitItem(
                            label = '', 
                            likelihood = 56, 
                            likelihood_score = 56, 
                            category = 'Toxic', 
                            subcategory = null, )
                        ], 
                    original_response = null, 
                    status = null, ),
                sentisight = openapi_client.models.imageexplicit_content_explicit_content_data_class.imageexplicit_contentExplicitContentDataClass(
                    nsfw_likelihood = 56, 
                    nsfw_likelihood_score = 56, 
                    items = [
                        openapi_client.models.explicit_item.ExplicitItem(
                            label = '', 
                            likelihood = 56, 
                            likelihood_score = 56, 
                            category = 'Toxic', 
                            subcategory = null, )
                        ], 
                    original_response = null, 
                    status = null, ),
                eden_ai = openapi_client.models.imageexplicit_content_explicit_content_data_class.imageexplicit_contentExplicitContentDataClass(
                    nsfw_likelihood = 56, 
                    nsfw_likelihood_score = 56, 
                    items = [
                        openapi_client.models.explicit_item.ExplicitItem(
                            label = '', 
                            likelihood = 56, 
                            likelihood_score = 56, 
                            category = 'Toxic', 
                            subcategory = null, )
                        ], 
                    original_response = null, 
                    status = null, )
            )
        else:
            return ImageexplicitContentResponseModel(
        )
        """

    def testImageexplicitContentResponseModel(self):
        """Test ImageexplicitContentResponseModel"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)


if __name__ == "__main__":
    unittest.main()
